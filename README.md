# TG_25_GestureOAK-D - Comprehensive Documentation

**English** | [æ—¥æœ¬èª](#æ—¥æœ¬èªç‰ˆ)

---

## ğŸŒŸ Project Overview

**TG_25_GestureOAK-D** is a real-time hand detection and swipe gesture recognition system optimized for the **Luxonis OAK-D-PRO** camera. The system leverages infrared (IR) stereo cameras with depth sensing to provide robust hand tracking in challenging lighting conditions, specifically designed for an operating distance of **80â€“160 cm**.

### Key Features
- **IR-Based Hand Detection**: Utilizes stereo IR cameras for dark environment operation
- **MediaPipe Integration**: Employs palm detection and hand landmark neural networks
- **Swipe Gesture Recognition**: Detects left-to-right swipe gestures with velocity and distance validation
- **UDP Communication**: Sends swipe notifications to external systems (`192.168.10.10:6001`)
- **Depth Filtering**: Uses stereo depth maps to filter false positives
- **Standalone Executables**: PyInstaller-based `.exe` files for deployment

---

## ğŸ“‹ Table of Contents

1. [What Has Been Implemented](#what-has-been-implemented)
2. [Technical Architecture](#technical-architecture)
3. [Prerequisites](#prerequisites)
4. [Environment Setup](#environment-setup)
5. [Installation Guide](#installation-guide)
6. [Application Architecture](#application-architecture)
7. [Running the Application](#running-the-application)
8. [Executable (.exe) Handling](#executable-exe-handling)
9. [Implementation Details](#implementation-details)
10. [Troubleshooting](#troubleshooting)
11. [Known Issues](#known-issues)
12. [Future Roadmap](#future-roadmap)

---

## ğŸ¯ What Has Been Implemented

### Core Components

#### 1. **OAK-D Camera Interface** (`oak_camera.py`)
- **Purpose**: Hardware abstraction layer for OAK-D device communication
- **Implementation**:
  - Dual-mode support (RGB and IR cameras)
  - Dynamic resolution configuration (640Ã—480 default)
  - Frame rate control (30 FPS target)
  - DepthAI pipeline initialization
  - Non-blocking frame acquisition
- **Technical Details**:
  - Uses `depthai` SDK for device communication
  - Implements `ColorCamera` and `MonoCamera` nodes
  - `ImageManip` node for real-time resizing
  - XLinkOut queues for host-device data transfer

#### 2. **Hand Detector** (`hand_detector.py`)
- **Purpose**: Real-time hand detection and landmark extraction
- **Implementation**:
  - **Palm Detection Network**: SSD-based palm localization (128Ã—128 input)
  - **Hand Landmark Network**: 21-point hand skeleton extraction (224Ã—224 input)
  - **Postprocessing Network**: NMS and score filtering
  - **Script Node**: On-device orchestration of detection pipeline
  - **IR Enhancement**: CLAHE + bilateral filtering for low-light conditions
  - **Depth-Based Filtering**: Distance-aware variance tolerance (300â€“2000 mm range)
- **Technical Pipeline**:
  ```
  IR Camera â†’ ImageManip (resize) â†’ Palm NN â†’ Postproc NN â†’ 
  Landmark NN â†’ Script (manager) â†’ Host Queue
  ```
- **Why This Approach**:
  - **IR cameras** provide consistent performance in dark environments
  - **On-device processing** reduces latency (no host-side inference)
  - **Depth filtering** eliminates false positives from background objects
  - **MediaPipe models** offer pre-trained accuracy for hand detection

#### 3. **Swipe Detector** (`swipe_detector.py`)
- **Purpose**: Robust left-to-right swipe gesture recognition
- **Implementation**:
  - **State Machine**: `IDLE â†’ DETECTING â†’ VALIDATING â†’ CONFIRMED`
  - **Trajectory Buffering**: Deque-based position history (18 frames)
  - **Timestamp-Based Velocity**: FPS-independent speed calculation
  - **Multi-Criteria Validation**:
    - Minimum distance: 90 pixels
    - Duration: 0.2â€“2.0 seconds
    - Velocity: 35â€“900 px/s
    - Y-axis deviation: â‰¤35% of X-axis travel
  - **Cooldown Mechanism**: 0.8s debounce to prevent repeated triggers
  - **UDP Notification**: Non-blocking socket communication
- **Why This Approach**:
  - **State machine** provides clear gesture progression tracking
  - **Velocity-based** detection is FPS-independent (robust across hardware)
  - **Multi-criteria** validation reduces false positives
  - **Cooldown** prevents rapid re-triggering during continuous motion

#### 4. **Applications**

##### Hand Tracking App (`hand_tracking_app.py`)
- **Purpose**: Integrated hand detection with swipe recognition
- **Features**:
  - Real-time hand landmark visualization
  - Bounding box rendering
  - Depth information overlay
  - Gesture classification (if enabled)
  - Swipe progress indicator
  - Statistics display (FPS, swipe count, filtered false positives)
- **Use Case**: Development, debugging, and demonstration

##### Motion Swipe App (`motion_swipe_app.py`)
- **Purpose**: Specialized swipe detection with trajectory visualization
- **Features**:
  - Swipe trail rendering (last 18 positions)
  - Detection zone overlay
  - Detailed progress metrics
  - Configurable sensitivity presets
- **Use Case**: Swipe gesture tuning and validation

##### Swipe Detection App (`swipe_detection_app.py`)
- **Purpose**: Minimal swipe-only interface
- **Features**:
  - Lightweight UI focused on swipe events
  - Real-time state display
  - Performance optimization for production
- **Use Case**: Production deployment

#### 5. **Launcher GUI** (`TG25_Launcher.py`)
- **Purpose**: User-friendly executable management
- **Implementation**:
  - Tkinter-based graphical interface
  - Start/Stop worker process control
  - Graceful shutdown via stop flag file
  - Process monitoring and status display
- **Why This Approach**:
  - **Separate launcher** prevents main app from blocking UI
  - **Stop flag file** enables clean shutdown without forced termination
  - **Process group management** ensures proper cleanup

#### 6. **Utility Modules**

##### FPS Counter (`FPS.py`)
- Rolling window FPS calculation
- Global average FPS tracking
- Elapsed time measurement

##### MediaPipe Utils (`mediapipe_utils.py`)
- Hand region data structures
- Landmark coordinate transformations
- Gesture recognition logic (finger counting)

##### Template Manager Script (`template_manager_script_solo.py`)
- On-device script template for DepthAI Script node
- Coordinates palm detection â†’ landmark extraction pipeline
- Implements NMS, region rotation, and score filtering

---

## ğŸ—ï¸ Technical Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Host Application                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  main.py (Menu Controller)                             â”‚ â”‚
â”‚  â”‚    â”œâ”€ Camera Test (oak_camera.py)                      â”‚ â”‚
â”‚  â”‚    â”œâ”€ Hand Tracking App                                â”‚ â”‚
â”‚  â”‚    â”œâ”€ Swipe Detection App                              â”‚ â”‚
â”‚  â”‚    â””â”€ Motion Swipe App                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Detection Layer                                       â”‚ â”‚
â”‚  â”‚    â”œâ”€ HandDetector (hand_detector.py)                  â”‚ â”‚
â”‚  â”‚    â””â”€ SwipeDetector (swipe_detector.py) â”€â”€â”€â”€â”€UDPâ”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                   DepthAI Pipeline
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OAK-D Device                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  IR Mono Cameras (LEFT + RIGHT)                        â”‚ â”‚
â”‚  â”‚    â†“                â†“                                  â”‚ â”‚
â”‚  â”‚  StereoDepth   MonoCamera â†’ ImageManip â†’ RGB888p       â”‚ â”‚
â”‚  â”‚    â†“                â†“                                  â”‚ â”‚
â”‚  â”‚  depth_out      cam_out (XLinkOut)                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Neural Networks (on VPU)                              â”‚ â”‚
â”‚  â”‚    â”œâ”€ Palm Detection NN (palm_detection_sh4.blob)      â”‚ â”‚
â”‚  â”‚    â”œâ”€ Postproc NN (PDPostProcessing_top2_sh1.blob)     â”‚ â”‚
â”‚  â”‚    â””â”€ Landmark NN (hand_landmark_lite_sh4.blob)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Script Node (Manager)                                 â”‚ â”‚
â”‚  â”‚    â”œâ”€ Coordinates NN execution                         â”‚ â”‚
â”‚  â”‚    â”œâ”€ Implements NMS and filtering                     â”‚ â”‚
â”‚  â”‚    â””â”€ Outputs marshalled results â†’ manager_out         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Sequence

```
1. IR Camera Capture (400p @ 30fps)
   â†“
2. ImageManip â†’ Resize to 640Ã—480, Convert to RGB888p
   â†“
3. IR Enhancement (CLAHE + Bilateral Filter)
   â†“
4. Palm Detection NN â†’ Bounding boxes
   â†“
5. Postprocessing NN â†’ NMS, Top-2 hands
   â†“
6. Landmark NN â†’ 21 keypoints per hand
   â†“
7. Script Manager â†’ Serialize results (marshal)
   â†“
8. Host Queue â†’ Python HandDetector.get_frame_and_hands()
   â†“
9. Depth Filtering â†’ Validate hand regions (300â€“2000mm)
   â†“
10. SwipeDetector.update() â†’ Trajectory analysis
    â†“
11. Swipe Confirmation â†’ UDP packet to 192.168.10.10:6001
```

---

## ğŸ“¦ Prerequisites

### Hardware Requirements
- **OAK-D-PRO** or **OAK-D** camera with IR stereo capability
- USB 3.0 port (minimum; USB 3.1+ recommended for higher throughput)
- Windows 10/11 (64-bit) or Linux (Ubuntu 20.04+)

### Software Requirements
- **Python 3.10â€“3.12** (3.12 recommended for latest features)
- **pip** package manager (latest version)
- **Git** (for cloning repository)
- **Virtual environment support** (venv module)

### System Libraries (Linux)
```bash
# Ubuntu/Debian
sudo apt-get install -y \
    libusb-1.0-0-dev \
    libudev-dev \
    python3-dev \
    python3-pip \
    libopencv-dev
```

### System Libraries (Windows)
- **Visual C++ Redistributable** (automatically installed with Python)
- **USB 3.0 drivers** (usually built-in; check Device Manager)

---

## ğŸ”§ Environment Setup

### Step 1: Clone Repository
```bash
git clone https://github.com/ShoumikMahbubRidoy/TG_25_GestureOAK-D.git
cd TG_25_GestureOAK-D
git checkout Hand-Gesture  # Ensure you're on the correct branch
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

**Why Virtual Environment?**
- Isolates project dependencies from system Python
- Prevents version conflicts with other projects
- Enables reproducible builds

### Step 3: Upgrade pip
```bash
python -m pip install --upgrade pip setuptools wheel
```

---

## ğŸ“¥ Installation Guide

### Install Dependencies
```bash
pip install -r requirements.txt
```

**Dependency Breakdown**:
- **depthai** (â‰¥2.24.0): OAK-D SDK for device communication and pipeline management
- **opencv-python** (â‰¥4.8.0): Computer vision library for frame processing and display
- **numpy** (â‰¥1.24.0): Numerical operations for landmark transformations
- **mediapipe** (â‰¥0.10.0): Pre-trained hand detection models (optional, for reference)
- **imutils** (â‰¥0.5.4): Convenience functions for OpenCV operations
- **pyyaml** (â‰¥6.0): Configuration file parsing (if using YAML configs)

### Verify Installation
```bash
# Check Python version
python --version  # Should show 3.10.x or 3.11.x or 3.12.x

# Check installed packages
pip list | grep -E "depthai|opencv|numpy"

# Test OAK-D connection
python -c "import depthai as dai; print(dai.__version__); print(dai.Device.getAllAvailableDevices())"
```

**Expected Output**:
```
2.24.0.0  # or later
[<depthai.DeviceInfo ...>]  # Should list your OAK-D device
```

### Environment Verification Script
```bash
python probe_dai.py
```

**What It Checks**:
- DepthAI library import
- OAK-D device enumeration
- USB connection speed
- Camera sensor availability

---

## ğŸ›ï¸ Application Architecture

### Module Structure
```
src/gesture_oak/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ oak_camera.py          # Camera abstraction layer
â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hand_detector.py       # MediaPipe-based hand detection
â”‚   â”œâ”€â”€ motion_detector.py     # Motion-based detection (alternative)
â”‚   â”œâ”€â”€ motion_swipe_detector.py
â”‚   â””â”€â”€ swipe_detector.py      # Gesture recognition logic
â”œâ”€â”€ logic/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gesture_classifier.py # Finger counting, gestures
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hand_tracking_app.py   # Main hand tracking demo
â”‚   â”œâ”€â”€ swipe_detection_app.py # Swipe-focused demo
â”‚   â””â”€â”€ motion_swipe_app.py    # Motion-based swipe demo
â””â”€â”€ utils/
    â”œâ”€â”€ FPS.py                 # FPS measurement
    â”œâ”€â”€ mediapipe_utils.py     # Data structures, helpers
    â””â”€â”€ template_manager_script_solo.py  # On-device script
```

### Entry Points
1. **main.py**: Interactive menu for running different applications
2. **run_hand_tracking.py**: Direct execution of hand tracking app
3. **TG25_Launcher.py**: GUI launcher for executable management
4. **probe_dai.py**: Device diagnostic tool

### Design Patterns

#### 1. **Factory Pattern** (OAKCamera)
```python
# oak_camera.py
class OAKCamera:
    def setup_pipeline(self) -> dai.Pipeline:
        # Dynamically creates RGB or IR pipeline based on use_rgb flag
```

#### 2. **State Machine** (SwipeDetector)
```python
# swipe_detector.py
class SwipeState(Enum):
    IDLE = "idle"
    DETECTING = "detecting"
    VALIDATING = "validating"
    CONFIRMED = "confirmed"
```

#### 3. **Template Method** (HandDetector)
```python
# hand_detector.py
def build_manager_script(self) -> str:
    # Uses string template for on-device script generation
    template = Template(raw_code)
    return template.substitute(params...)
```

---

## ğŸš€ Running the Application

### Method 1: Interactive Menu (Recommended)
```bash
python main.py
```

**Menu Options**:
```
1. Test camera connection        # Verify OAK-D setup
2. Run hand tracking app         # Full-featured hand detection + swipe
3. Run swipe detection app       # Swipe-focused interface
4. Run motion-based swipe        # Alternative motion detection
5. Exit
```

**When to Use Each**:
- **Option 1**: First-time setup, troubleshooting connection issues
- **Option 2**: Development, debugging, demonstration
- **Option 3**: Production swipe detection
- **Option 4**: Experimental motion-based approach

### Method 2: Direct Execution
```bash
# Hand tracking with swipe detection
python run_hand_tracking.py

# Or via module
python -m gesture_oak.apps.hand_tracking_app
```

### Method 3: Using UV (Fast Python Package Manager)
```bash
# Install uv if not already installed
pip install uv

# Run with uv (faster startup)
uv run python main.py
```

### Runtime Controls

#### Keyboard Shortcuts
- **`q`**: Quit application
- **`s`**: Save current frame to disk (JPEG format)
- **`r`**: Reset swipe statistics

#### Console Output
```
OAK-D Hand Detection Demo with Swipe Detection
=============================================
Press 'q' to quit
Press 's' to save current frame
Press 'r' to reset swipe statistics

Connected to device: OAK-D-PRO
USB Speed: SUPER_SPEED
Hand detection started. Showing live preview...

Hand 1: right (confidence: 0.957)
  Gesture: FIVE
 LEFT-TO-RIGHT SWIPE DETECTED! (Total: 1)
```

### Expected Performance
- **FPS**: 25â€“30 FPS (IR mode on OAK-D-PRO)
- **Latency**: ~50â€“80ms (camera to display)
- **Detection Range**: 80â€“160 cm optimal, 40â€“200 cm extended
- **Swipe Success Rate**: ~95% under good conditions

---

## ğŸ—‚ï¸ Executable (.exe) Handling

### Building Executables

The project uses **PyInstaller** to create standalone executables for Windows deployment.

#### Prerequisites for Building
```bash
pip install pyinstaller
```

#### Build Scripts

##### 1. Build Hand Tracking Worker
```bash
# Windows
build.bat

# Or manually
pyinstaller TG25_HandTracking.spec
```

**Spec File Highlights** (`TG25_HandTracking.spec`):
```python
a = Analysis(
    ['run_hand_tracking.py'],
    pathex=[],
    binaries=[],
    datas=[
        ('models', 'models'),  # Bundle neural network blobs
        ('src/gesture_oak/utils/template_manager_script_solo.py',
         'src/gesture_oak/utils'),
    ],
    hiddenimports=[
        'depthai',
        'cv2',
        'numpy',
        # ... all dependencies
    ],
    ...
)
```

##### 2. Build Launcher GUI
```bash
pyinstaller TG25_Launcher.spec
```

##### 3. Build Diagnostic Tool
```bash
pyinstaller probe_dai.spec
```

### Executable Distribution

After building, the `dist/` folder contains:
```
dist/
â”œâ”€â”€ TG25_HandTracking/
â”‚   â”œâ”€â”€ TG25_HandTracking.exe  # Main worker application
â”‚   â”œâ”€â”€ models/                # Neural network blobs
â”‚   â””â”€â”€ [dependencies]         # DLLs, libraries
â”œâ”€â”€ TG25_Launcher.exe          # GUI launcher
â””â”€â”€ probe_dai.exe              # Diagnostic tool
```

### Deployment Instructions

1. **Copy entire folder** to target machine:
   ```
   TG25_GestureOAK-D_Deployment/
   â”œâ”€â”€ TG25_Launcher.exe
   â”œâ”€â”€ TG25_HandTracking.exe
   â”œâ”€â”€ models/
   â””â”€â”€ (all DLLs from dist/)
   ```

2. **Run `TG25_Launcher.exe`** to start the GUI

3. **Click "Start Hand Tracking"** to launch worker

### Troubleshooting Executables

#### Issue: "Cannot find models folder"
**Solution**: Ensure `models/` is in the same directory as `.exe`

#### Issue: "Import Error: No module named 'depthai'"
**Solution**: PyInstaller may have missed dependencies. Add to `hiddenimports` in `.spec` file:
```python
hiddenimports=[
    'depthai',
    'depthai._version',  # Add submodules
    ...
]
```

#### Issue: Worker doesn't stop gracefully
**Solution**: Check stop flag file path:
```python
# In TG25_Launcher.py
stop_file = Path(_exe_dir()) / "TG25_STOP.flag"

# In run_hand_tracking.py
stop_file_path = os.environ.get("TG25_STOP_FILE", "")
```

---

## ğŸ› ï¸ Implementation Details

### Hand Detection Pipeline

#### 1. Camera Initialization
```python
# hand_detector.py
cam_left = pipeline.createMonoCamera()
cam_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
cam_left.setBoardSocket(dai.CameraBoardSocket.LEFT)
cam_left.setFps(30)

cam_right = pipeline.createMonoCamera()
cam_right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
cam_right.setBoardSocket(dai.CameraBoardSocket.RIGHT)
cam_right.setFps(30)
```

**Why IR Cameras**:
- Consistent performance in low light
- Less affected by color variations (skin tone, clothing)
- Native 400p resolution matches MediaPipe input requirements

#### 2. Stereo Depth Configuration
```python
depth = pipeline.createStereoDepth()
depth.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
depth.initialConfig.setMedianFilter(dai.MedianFilter.KERNEL_7x7)
depth.setLeftRightCheck(True)    # Eliminates invalid disparities
depth.setSubpixel(True)          # Improves depth precision
```

**Technical Explanation**:
- **HIGH_DENSITY**: Optimized for indoor scenes with small objects (hands)
- **7Ã—7 Median Filter**: Removes speckle noise from depth map
- **Left-Right Check**: Validates disparity consistency between stereo pairs
- **Subpixel**: Enables fractional disparity values for smoother depth

#### 3. IR Frame Enhancement
```python
def enhance_ir_frame(self, frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
    
    # CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # Bilateral filter (edge-preserving smoothing)
    enhanced = cv2.bilateralFilter(enhanced, 5, 50, 50)
    
    return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)
```

**Why This Approach**:
- **CLAHE**: Enhances local contrast without over-amplifying noise
- **clipLimit=2.0**: Prevents excessive amplification in homogeneous regions
- **tileGridSize=(8,8)**: Balances local and global contrast
- **Bilateral Filter**: Smooths noise while preserving hand edges

#### 4. Depth-Based Filtering
```python
def filter_hands_by_depth(self, hands, depth_frame):
    for hand in hands:
        cx, cy = hand.rect_x_center_a, hand.rect_y_center_a
        d_center = depth_frame[cy, cx]
        
        # Valid range: 300â€“2000mm (30cm â€“ 2m)
        if not (300 <= d_center <= 2000):
            continue
        
        # Region of interest around hand center
        half = 18 if d_center < 1000 else 26  # Larger ROI for distant hands
        roi = depth_frame[cy-half:cy+half, cx-half:cx+half]
        
        avg = np.mean(roi[roi > 0])
        std = np.std(roi[roi > 0])
        
        # Distance-aware tolerance
        std_limit = 80.0 + 0.08 * max(0.0, (avg - 800.0))
        if std <= std_limit:
            hand.depth = avg
            hand.depth_confidence = 1.0 - (std / std_limit)
```

**Technical Rationale**:
- **Variable std_limit**: Farther hands have less depth precision
- **ROI size scaling**: Adapts to hand apparent size at different distances
- **Confidence score**: Quantifies reliability of depth measurement

### Swipe Detection Algorithm

#### State Transition Logic
```python
IDLE:
    - Buffer hand positions with timestamps
    - Check for consistent rightward motion (3 consecutive frames)
    - Transition to DETECTING if motion detected

DETECTING:
    - Continue buffering trajectory
    - Calculate accumulated distance
    - Timeout if duration > max_duration (2.0s)
    - Abort if movement reverses left
    - Transition to VALIDATING when distance >= min_distance (90px)

VALIDATING:
    - Verify duration within [0.2s, 2.0s]
    - Calculate average velocity: distance / duration
    - Check velocity bounds [35 px/s, 900 px/s]
    - Verify Y-axis deviation â‰¤ 35% of X-travel
    - Confirm no significant backward motion (< -12px jumps)
    - Transition to CONFIRMED if all checks pass

CONFIRMED:
    - Increment swipe counter
    - Send UDP packet "Swipe" to 192.168.10.10:6001
    - Apply cooldown (0.8s) to prevent rapid re-triggers
    - Transition back to IDLE
```

#### Velocity Calculation
```python
# FPS-independent velocity (pixels per second)
times = np.array(self.time_buffer)
poses = np.array(self.position_buffer)

total_dx = poses[-1, 0] - poses[0, 0]  # Horizontal displacement
duration = times[-1] - times[0]        # Elapsed time
velocity = total_dx / duration         # px/s
```

**Why Timestamp-Based**:
- Independent of frame rate variations
- Handles dropped frames gracefully
- Provides accurate speed measurement

---

## ğŸ› Troubleshooting

### Issue 1: Camera Not Detected

**Symptoms**:
```
Failed to connect to OAK-D: [X_LINK_DEVICE_NOT_FOUND]
```

**Solutions**:

1. **Check USB Connection**:
   ```bash
   # Linux
   lsusb | grep "03e7"  # Luxonis VID
   
   # Windows (Device Manager)
   # Look for "Movidius MyriadX" or "OAK-D" under USB devices
   ```

2. **Update USB Drivers** (Windows):
   - Download Zadig: https://zadig.akeo.ie/
   - Replace driver with WinUSB

3. **Grant USB Permissions** (Linux):
   ```bash
   echo 'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"' | sudo tee /etc/udev/rules.d/80-movidius.rules
   sudo udevadm control --reload-rules && sudo udevadm trigger
   ```

4. **Test with Diagnostic Tool**:
   ```bash
   python probe_dai.py
   ```

### Issue 2: Low FPS / Stuttering

**Symptoms**:
- Frame rate drops below 20 FPS
- Jerky camera preview

**Solutions**:

1. **Check USB Speed**:
   ```python
   # Should show USB3 SUPER_SPEED or SUPER_PLUS
   device.getUsbSpeed()
   ```

2. **Reduce Queue Sizes** (if buffering):
   ```python
   # In hand_detector.py
   self.q_video = self.device.getOutputQueue(
       name="cam_out", 
       maxSize=2,  # Reduce from 4 to 2
       blocking=False
   )
   ```

3. **Disable IR Enhancement** (for testing):
   ```python
   # Comment out in hand_detector.py
   # frame = self.enhance_ir_frame(raw_frame)
   frame = raw_frame
   ```

4. **Optimize OpenCV**:
   ```python
   import cv2
   cv2.setUseOptimized(True)
   cv2.setNumThreads(0)  # Auto-detect optimal thread count
   ```

### Issue 3: False Positive Swipe Detections

**Symptoms**:
- Swipes trigger without hand movement
- Random objects cause detections

**Solutions**:

1. **Increase Minimum Distance**:
   ```python
   swipe_detector = SwipeDetector(
       min_distance=120,  # Increase from 90
   )
   ```

2. **Stricter Y-Deviation**:
   ```python
   swipe_detector = SwipeDetector(
       max_y_deviation=0.25,  # Reduce from 0.35
   )
   ```

3. **Tighten Velocity Bounds**:
   ```python
   swipe_detector = SwipeDetector(
       min_velocity=50,   # Increase from 35
       max_velocity=700,  # Reduce from 900
   )
   ```

4. **Enable Stricter Depth Filtering**:
   ```python
   # In hand_detector.py
   std_limit = 60.0 + 0.06 * max(0.0, (avg - 800.0))  # Reduce tolerance
   ```

### Issue 4: Hand Not Detected at Distance

**Symptoms**:
- Hand visible on screen but no detection at 100+ cm
- Works only at close range (<80 cm)

**Solutions**:

1. **Lower Palm Detection Threshold**:
   ```python
   detector = HandDetector(
       pd_score_thresh=0.08,  # Reduce from 0.10
   )
   ```

2. **Increase Buffer Size** (more history):
   ```python
   swipe_detector = SwipeDetector(
       buffer_size=24,  # Increase from 18
   )
   ```

3. **Adjust Depth Range**:
   ```python
   # In hand_detector.py - filter_hands_by_depth()
   if not (200 <= d_center <= 2500):  # Extend range
   ```

4. **Verify IR Illumination**:
   - OAK-D-PRO has active IR emitters
   - Check if IR LEDs are visible (use phone camera)

### Issue 5: "ImportError" on Executable

**Symptoms**:
```
ImportError: No module named 'depthai'
ModuleNotFoundError: No module named 'cv2'
```

**Solutions**:

1. **Rebuild with All Hidden Imports**:
   ```python
   # In .spec file
   hiddenimports=[
       'depthai',
       'cv2',
       'numpy',
       'numpy.core',
       'numpy.core._multiarray_umath',
       'mediapipe',
       'marshal',
       'collections',
       'collections.abc',
       'socket',
       'time',
       'pathlib',
   ]
   ```

2. **Bundle Binary Dependencies**:
   ```python
   # In .spec file
   binaries=[
       (r'C:\path\to\.venv\Lib\site-packages\depthai\*.dll', 'depthai'),
   ]
   ```

3. **Use PyInstaller Hooks**:
   ```bash
   pip install pyinstaller-hooks-contrib
   pyinstaller --additional-hooks-dir=. TG25_HandTracking.spec
   ```

### Issue 6: UDP Packets Not Received

**Symptoms**:
- Swipe detected but no network traffic
- Target system doesn't receive "Swipe" message

**Solutions**:

1. **Verify Network Configuration**:
   ```bash
   # Test UDP connectivity
   # On target (192.168.10.10):
   nc -u -l 6001
   
   # On source machine:
   echo "test" | nc -u 192.168.10.10 6001
   ```

2. **Check Firewall Rules**:
   ```bash
   # Windows
   netsh advfirewall firewall add rule name="Allow UDP 6001" dir=out action=allow protocol=UDP localport=6001
   
   # Linux
   sudo ufw allow out 6001/udp
   ```

3. **Test Socket Directly**:
   ```python
   import socket
   sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
   sock.sendto(b"Test", ("192.168.10.10", 6001))
   print("Sent test packet")
   ```

4. **Enable Socket Debug**:
   ```python
   # In swipe_detector.py
   try:
       self._udp_sock.sendto(b"Swipe", self._udp_target)
       print(f"UDP sent to {self._udp_target}")
   except Exception as e:
       print(f"UDP error: {e}")
   ```

### Issue 7: Launcher Can't Stop Worker

**Symptoms**:
- "Stop" button doesn't terminate worker
- Worker process remains after launcher exit

**Solutions**:

1. **Verify Stop Flag Path**:
   ```python
   # In TG25_Launcher.py
   print(f"Stop flag: {self.stop_file}")
   
   # In run_hand_tracking.py
   stop_file_path = os.environ.get("TG25_STOP_FILE", "")
   print(f"Monitoring stop flag: {stop_file_path}")
   ```

2. **Check File System Permissions**:
   ```bash
   # Ensure launcher can write to working directory
   touch TG25_STOP.flag && rm TG25_STOP.flag
   ```

3. **Force Termination** (as last resort):
   ```python
   # In TG25_Launcher.py - stop_worker()
   import psutil
   try:
       proc = psutil.Process(self.proc.pid)
       for child in proc.children(recursive=True):
           child.kill()
       proc.kill()
   except Exception as e:
       print(f"Force kill error: {e}")
   ```

---

## âš ï¸ Known Issues

### 1. FPS Counter Anomaly
**Description**: Occasionally reports unrealistic FPS (>100,000)  
**Root Cause**: Rolling window calculation edge case when `elapsed < 1e-6`  
**Impact**: Visual only; doesn't affect performance  
**Workaround**: Use global average FPS instead  
**Status**: Low priority fix

### 2. Left Hand Detection Instability
**Description**: Left hand less reliable beyond 100 cm  
**Root Cause**: MediaPipe model bias toward right hand  
**Impact**: Reduced detection range for left hand  
**Workaround**: Use right hand for distant operations  
**Status**: Investigating alternative models

### 3. Background False Positives
**Description**: Clothing, hair, or ears occasionally trigger hand detection  
**Root Cause**: IR reflectance similarities  
**Impact**: Occasional false detections  
**Workaround**: Use depth filtering, stricter thresholds  
**Status**: Ongoing tuning

### 4. Depth Map Holes
**Description**: Depth unavailable in certain frame regions  
**Root Cause**: Insufficient texture in stereo images  
**Impact**: Some valid hands fail depth filtering  
**Workaround**: Lower `std_limit` tolerance  
**Status**: Hardware limitation

---

## ğŸ—ºï¸ Future Roadmap

### Phase 1: Gesture Expansion (Q2 2024)
- [ ] Finger count recognition (1-5)
- [ ] Static gestures (peace, thumbs-up, OK)
- [ ] Fist/palm open detection
- [ ] Dynamic gesture vocabulary

### Phase 2: Multi-Hand Support (Q3 2024)
- [ ] Simultaneous tracking of 2 hands
- [ ] Hand-hand interaction gestures
- [ ] Coordinated swipe detection

### Phase 3: Robustness Improvements (Q4 2024)
- [ ] Custom training dataset collection
- [ ] Fine-tuned MediaPipe models
- [ ] Adaptive thresholding based on environment
- [ ] Machine learning for false positive reduction

### Phase 4: Extended Features (2025)
- [ ] 3D gesture recognition using world landmarks
- [ ] Pose estimation integration
- [ ] Gesture macros and sequences
- [ ] Remote configuration via web UI

### Phase 5: Optimization (Ongoing)
- [ ] Fix FPS counter edge cases
- [ ] Reduce latency to <30ms
- [ ] GPU acceleration for preprocessing
- [ ] Custom neural network quantization

---

# æ—¥æœ¬èªç‰ˆ

## ğŸŒŸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

**TG_25_GestureOAK-D** ã¯ã€**Luxonis OAK-D-PRO** ã‚«ãƒ¡ãƒ©å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ‰‹æ¤œå‡ºãŠã‚ˆã³ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€èµ¤å¤–ç·šï¼ˆIRï¼‰ã‚¹ãƒ†ãƒ¬ã‚ªã‚«ãƒ¡ãƒ©ã¨æ·±åº¦ã‚»ãƒ³ã‚·ãƒ³ã‚°ã‚’æ´»ç”¨ã—ã€å³ã—ã„ç…§æ˜æ¡ä»¶ä¸‹ã§ã‚‚å …ç‰¢ãªæ‰‹è¿½è·¡ã‚’å®Ÿç¾ã—ã¾ã™ã€‚**80ã€œ160 cm** ã®å‹•ä½œè·é›¢ã«ç‰¹åŒ–ã—ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚

### ä¸»ãªæ©Ÿèƒ½
- **IRãƒ™ãƒ¼ã‚¹æ‰‹æ¤œå‡º**: ã‚¹ãƒ†ãƒ¬ã‚ªIRã‚«ãƒ¡ãƒ©ã«ã‚ˆã‚‹æš—æ‰€ç’°å¢ƒã§ã®å‹•ä½œ
- **MediaPipeçµ±åˆ**: ãƒ‘ãƒ¼ãƒ æ¤œå‡ºãŠã‚ˆã³ãƒãƒ³ãƒ‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ¡ç”¨
- **ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜**: é€Ÿåº¦ã¨è·é›¢æ¤œè¨¼ã‚’ä¼´ã†å·¦ã‹ã‚‰å³ã¸ã®ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡º
- **UDPé€šä¿¡**: å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ`192.168.10.10:6001`ï¼‰ã¸ã®ã‚¹ãƒ¯ã‚¤ãƒ—é€šçŸ¥é€ä¿¡
- **æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: ã‚¹ãƒ†ãƒ¬ã‚ªæ·±åº¦ãƒãƒƒãƒ—ã«ã‚ˆã‚‹èª¤æ¤œå‡ºé™¤å»
- **ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ¼ãƒ³å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«**: PyInstallerãƒ™ãƒ¼ã‚¹ã®`.exe`å±•é–‹

---

## ğŸ“‹ ç›®æ¬¡

1. [å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½](#å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½)
2. [æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£-1)
3. [å‰ææ¡ä»¶](#å‰ææ¡ä»¶-1)
4. [ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—-1)
5. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰-1)
6. [ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£-1)
7. [ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ](#ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ)
8. [å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.exeï¼‰ã®å–ã‚Šæ‰±ã„](#å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«exeã®å–ã‚Šæ‰±ã„)
9. [å®Ÿè£…ã®è©³ç´°](#å®Ÿè£…ã®è©³ç´°)
10. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°-1)
11. [æ—¢çŸ¥ã®å•é¡Œ](#æ—¢çŸ¥ã®å•é¡Œ-1)
12. [ä»Šå¾Œã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—](#ä»Šå¾Œã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—-1)

---

## ğŸ¯ å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½

### ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 1. **OAK-Dã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹** (`oak_camera.py`)
- **ç›®çš„**: OAK-Dãƒ‡ãƒã‚¤ã‚¹é€šä¿¡ã®ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼
- **å®Ÿè£…å†…å®¹**:
  - ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼ˆRGBãŠã‚ˆã³IRã‚«ãƒ¡ãƒ©ï¼‰
  - å‹•çš„è§£åƒåº¦è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ640Ã—480ï¼‰
  - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡ï¼ˆç›®æ¨™30 FPSï¼‰
  - DepthAIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
  - ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
- **æŠ€è¡“è©³ç´°**:
  - `depthai` SDKã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¹é€šä¿¡
  - `ColorCamera` ãŠã‚ˆã³ `MonoCamera` ãƒãƒ¼ãƒ‰ã®å®Ÿè£…
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒªã‚µã‚¤ã‚ºã®ãŸã‚ã® `ImageManip` ãƒãƒ¼ãƒ‰
  - ãƒ›ã‚¹ãƒˆãƒ»ãƒ‡ãƒã‚¤ã‚¹é–“ãƒ‡ãƒ¼ã‚¿è»¢é€ç”¨XLinkOutã‚­ãƒ¥ãƒ¼

#### 2. **ãƒãƒ³ãƒ‰æ¤œå‡ºå™¨** (`hand_detector.py`)
- **ç›®çš„**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ‰‹æ¤œå‡ºãŠã‚ˆã³ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡º
- **å®Ÿè£…å†…å®¹**:
  - **ãƒ‘ãƒ¼ãƒ æ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: SSDãƒ™ãƒ¼ã‚¹ã®æ‰‹ã®ã²ã‚‰ä½ç½®ç‰¹å®šï¼ˆ128Ã—128å…¥åŠ›ï¼‰
  - **ãƒãƒ³ãƒ‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: 21ç‚¹ã®æ‰‹éª¨æ ¼æŠ½å‡ºï¼ˆ224Ã—224å…¥åŠ›ï¼‰
  - **å¾Œå‡¦ç†ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: NMSãŠã‚ˆã³ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  - **ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒãƒ¼ãƒ‰**: ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
  - **IRå¼·èª¿å‡¦ç†**: ä½ç…§åº¦æ¡ä»¶å‘ã‘CLAHE + ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  - **æ·±åº¦ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: è·é›¢å¯¾å¿œåˆ†æ•£è¨±å®¹ï¼ˆ300ã€œ2000 mmç¯„å›²ï¼‰
- **æŠ€è¡“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**:
  ```
  IRã‚«ãƒ¡ãƒ© â†’ ImageManipï¼ˆãƒªã‚µã‚¤ã‚ºï¼‰ â†’ Palm NN â†’ Postproc NN â†’ 
  Landmark NN â†’ Scriptï¼ˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰ â†’ ãƒ›ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼
  ```
- **ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ãŸç†ç”±**:
  - **IRã‚«ãƒ¡ãƒ©** ã¯æš—æ‰€ç’°å¢ƒã§ä¸€è²«ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æä¾›
  - **ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹å‡¦ç†** ã«ã‚ˆã‚Šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å‰Šæ¸›ï¼ˆãƒ›ã‚¹ãƒˆå´æ¨è«–ãªã—ï¼‰
  - **æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°** ã«ã‚ˆã‚ŠèƒŒæ™¯ç‰©ä½“ã‹ã‚‰ã®èª¤æ¤œå‡ºã‚’æ’é™¤
  - **MediaPipeãƒ¢ãƒ‡ãƒ«** ã¯æ‰‹æ¤œå‡ºç”¨ã®äº‹å‰å­¦ç¿’æ¸ˆã¿ç²¾åº¦ã‚’æä¾›

#### 3. **ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºå™¨** (`swipe_detector.py`)
- **ç›®çš„**: å …ç‰¢ãªå·¦ã‹ã‚‰å³ã¸ã®ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜
- **å®Ÿè£…å†…å®¹**:
  - **ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³**: `IDLE â†’ DETECTING â†’ VALIDATING â†’ CONFIRMED`
  - **è»Œè·¡ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°**: Dequeãƒ™ãƒ¼ã‚¹ä½ç½®å±¥æ­´ï¼ˆ18ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
  - **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹é€Ÿåº¦**: FPSéä¾å­˜é€Ÿåº¦è¨ˆç®—
  - **å¤šåŸºæº–æ¤œè¨¼**:
    - æœ€å°è·é›¢: 90ãƒ”ã‚¯ã‚»ãƒ«
    - æŒç¶šæ™‚é–“: 0.2ã€œ2.0ç§’
    - é€Ÿåº¦: 35ã€œ900 px/s
    - Yè»¸åå·®: Xè»¸ç§»å‹•ã®â‰¤35%
  - **ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ **: 0.8ç§’ãƒ‡ãƒã‚¦ãƒ³ã‚¹ã«ã‚ˆã‚‹é€£ç¶šãƒˆãƒªã‚¬ãƒ¼é˜²æ­¢
  - **UDPé€šçŸ¥**: ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã‚½ã‚±ãƒƒãƒˆé€šä¿¡
- **ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ãŸç†ç”±**:
  - **ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³** ã«ã‚ˆã‚Šæ˜ç¢ºãªã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼é€²è¡Œè¿½è·¡ãŒå¯èƒ½
  - **é€Ÿåº¦ãƒ™ãƒ¼ã‚¹** æ¤œå‡ºã¯FPSéä¾å­˜ï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é–“ã§å …ç‰¢ï¼‰
  - **å¤šåŸºæº–** æ¤œè¨¼ã«ã‚ˆã‚Šèª¤æ¤œå‡ºã‚’å‰Šæ¸›
  - **ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³** ã«ã‚ˆã‚Šé€£ç¶šå‹•ä½œä¸­ã®æ€¥é€Ÿãªå†ãƒˆãƒªã‚¬ãƒ¼ã‚’é˜²æ­¢

#### 4. **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**

##### ãƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ—ãƒª (`hand_tracking_app.py`)
- **ç›®çš„**: ã‚¹ãƒ¯ã‚¤ãƒ—èªè­˜çµ±åˆæ‰‹æ¤œå‡º
- **æ©Ÿèƒ½**:
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ‰‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–
  - ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
  - æ·±åº¦æƒ…å ±ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
  - ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼åˆ†é¡ï¼ˆæœ‰åŠ¹æ™‚ï¼‰
  - ã‚¹ãƒ¯ã‚¤ãƒ—é€²è¡ŒçŠ¶æ³ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
  - çµ±è¨ˆè¡¨ç¤ºï¼ˆFPSã€ã‚¹ãƒ¯ã‚¤ãƒ—å›æ•°ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸèª¤æ¤œå‡ºï¼‰
- **ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: é–‹ç™ºã€ãƒ‡ãƒãƒƒã‚°ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

##### ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¢ãƒ—ãƒª (`motion_swipe_app.py`)
- **ç›®çš„**: è»Œè·¡å¯è¦–åŒ–ã‚’ä¼´ã†ç‰¹åŒ–å‹ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡º
- **æ©Ÿèƒ½**:
  - ã‚¹ãƒ¯ã‚¤ãƒ—ãƒˆãƒ¬ã‚¤ãƒ«æç”»ï¼ˆç›´è¿‘18ä½ç½®ï¼‰
  - æ¤œå‡ºã‚¾ãƒ¼ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
  - è©³ç´°é€²è¡ŒçŠ¶æ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  - è¨­å®šå¯èƒ½ãªæ„Ÿåº¦ãƒ—ãƒªã‚»ãƒƒãƒˆ
- **ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¤œè¨¼

##### ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºã‚¢ãƒ—ãƒª (`swipe_detection_app.py`)
- **ç›®çš„**: æœ€å°é™ã®ã‚¹ãƒ¯ã‚¤ãƒ—å°‚ç”¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **æ©Ÿèƒ½**:
  - ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¤ãƒ™ãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ãŸè»½é‡UI
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ…‹è¡¨ç¤º
  - æœ¬ç•ªç’°å¢ƒå‘ã‘ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- **ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

#### 5. **ãƒ©ãƒ³ãƒãƒ£ãƒ¼GUI** (`TG25_Launcher.py`)
- **ç›®çš„**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
- **å®Ÿè£…å†…å®¹**:
  - Tkinterãƒ™ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
  - ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹/åœæ­¢åˆ¶å¾¡
  - åœæ­¢ãƒ•ãƒ©ã‚°ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ã®ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
  - ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ãŠã‚ˆã³ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
- **ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ãŸç†ç”±**:
  - **åˆ¥å€‹ã®ãƒ©ãƒ³ãƒãƒ£ãƒ¼** ã«ã‚ˆã‚Šãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªãŒUIã‚’ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ã®ã‚’é˜²æ­¢
  - **åœæ­¢ãƒ•ãƒ©ã‚°ãƒ•ã‚¡ã‚¤ãƒ«** ã«ã‚ˆã‚Šå¼·åˆ¶çµ‚äº†ãªã—ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãŒå¯èƒ½
  - **ãƒ—ãƒ­ã‚»ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†** ã«ã‚ˆã‚Šé©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ä¿è¨¼

#### 6. **ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**

##### FPSã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ (`FPS.py`)
- ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦FPSè¨ˆç®—
- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡FPSè¿½è·¡
- çµŒéæ™‚é–“æ¸¬å®š

##### MediaPipe Utils (`mediapipe_utils.py`)
- æ‰‹é ˜åŸŸãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™å¤‰æ›
- ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæŒ‡ã‚«ã‚¦ãƒ³ãƒˆï¼‰

##### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (`template_manager_script_solo.py`)
- DepthAI Scriptãƒãƒ¼ãƒ‰ç”¨ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- ãƒ‘ãƒ¼ãƒ æ¤œå‡º â†’ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®èª¿æ•´
- NMSã€é ˜åŸŸå›è»¢ã€ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè£…

---

## ğŸ—ï¸ æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ãƒ›ã‚¹ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  main.py (ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼)                        â”‚ â”‚
â”‚  â”‚    â”œâ”€ ã‚«ãƒ¡ãƒ©ãƒ†ã‚¹ãƒˆ (oak_camera.py)                      â”‚ â”‚
â”‚  â”‚    â”œâ”€ ãƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ—ãƒª                        ã€€ â”‚ â”‚
â”‚  â”‚    â”œâ”€ ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºã‚¢ãƒ—ãƒª                                â”‚ â”‚
â”‚  â”‚    â””â”€ ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¯ã‚¤ãƒ—ã‚¢ãƒ—ãƒª                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  æ¤œå‡ºãƒ¬ã‚¤ãƒ¤ãƒ¼                                           â”‚ â”‚
â”‚  â”‚    â”œâ”€ HandDetector (hand_detector.py)                  â”‚ â”‚
â”‚  â”‚    â””â”€ SwipeDetector (swipe_detector.py) â”€â”€â”€â”€â”€UDPâ”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                   DepthAIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OAK-Dãƒ‡ãƒã‚¤ã‚¹                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  IRãƒ¢ãƒã‚«ãƒ¡ãƒ© (LEFT + RIGHT)                            â”‚ â”‚
â”‚  â”‚    â†“                â†“                                  â”‚ â”‚
â”‚  â”‚  StereoDepth   MonoCamera â†’ ImageManip â†’ RGB888p       â”‚ â”‚
â”‚  â”‚    â†“                â†“                                  â”‚ â”‚
â”‚  â”‚  depth_out      cam_out (XLinkOut)                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (VPUä¸Š)                          â”‚ â”‚
â”‚  â”‚    â”œâ”€ ãƒ‘ãƒ¼ãƒ æ¤œå‡ºNN (palm_detection_sh4.blob)            â”‚ â”‚
â”‚  â”‚    â”œâ”€ å¾Œå‡¦ç†NN (PDPostProcessing_top2_sh1.blob)         â”‚ â”‚
â”‚  â”‚    â””â”€ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯NN (hand_landmark_lite_sh4.blob)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒãƒ¼ãƒ‰ (ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼)                          â”‚ â”‚
â”‚  â”‚    â”œâ”€ NNå®Ÿè¡Œã®èª¿æ•´                                      â”‚ â”‚
â”‚  â”‚    â”œâ”€ NMSãŠã‚ˆã³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè£…                       â”‚ â”‚
â”‚  â”‚    â””â”€ ãƒãƒ¼ã‚·ãƒ£ãƒ«ã•ã‚ŒãŸçµæœã‚’å‡ºåŠ› â†’ manager_out            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹

```
1. IRã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£ (400p @ 30fps)
   â†“
2. ImageManip â†’ 640Ã—480ã«ãƒªã‚µã‚¤ã‚ºã€RGB888pã«å¤‰æ›
   â†“
3. IRå¼·èª¿å‡¦ç† (CLAHE + ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼)
   â†“
4. ãƒ‘ãƒ¼ãƒ æ¤œå‡ºNN â†’ ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
   â†“
5. å¾Œå‡¦ç†NN â†’ NMSã€ä¸Šä½2ã¤ã®æ‰‹
   â†“
6. ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯NN â†’ æ‰‹ã”ã¨ã«21ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
   â†“
7. ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ â†’ çµæœã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º (marshal)
   â†“
8. ãƒ›ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼ â†’ Python HandDetector.get_frame_and_hands()
   â†“
9. æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° â†’ æ‰‹é ˜åŸŸã‚’æ¤œè¨¼ (300ã€œ2000mm)
   â†“
10. SwipeDetector.update() â†’ è»Œè·¡åˆ†æ
    â†“
11. ã‚¹ãƒ¯ã‚¤ãƒ—ç¢ºèª â†’ 192.168.10.10:6001ã¸UDPãƒ‘ã‚±ãƒƒãƒˆé€ä¿¡
```

---

## ğŸ“¦ å‰ææ¡ä»¶

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶
- IRã‚¹ãƒ†ãƒ¬ã‚ªæ©Ÿèƒ½ä»˜ã **OAK-D-PRO** ã¾ãŸã¯ **OAK-D** ã‚«ãƒ¡ãƒ©
- USB 3.0ãƒãƒ¼ãƒˆï¼ˆæœ€å°; ã‚ˆã‚Šé«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãŸã‚USB 3.1+æ¨å¥¨ï¼‰
- Windows 10/11ï¼ˆ64ãƒ“ãƒƒãƒˆï¼‰ã¾ãŸã¯Linuxï¼ˆUbuntu 20.04+ï¼‰

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¦ä»¶
- **Python 3.10ã€œ3.12**ï¼ˆæœ€æ–°æ©Ÿèƒ½ã®ãŸã‚3.12æ¨å¥¨ï¼‰
- **pip** ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆæœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
- **Git**ï¼ˆãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ï¼‰
- **ä»®æƒ³ç’°å¢ƒã‚µãƒãƒ¼ãƒˆ**ï¼ˆvenvãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰

### ã‚·ã‚¹ãƒ†ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (Linux)
```bash
# Ubuntu/Debian
sudo apt-get install -y \
    libusb-1.0-0-dev \
    libudev-dev \
    python3-dev \
    python3-pip \
    libopencv-dev
```

### ã‚·ã‚¹ãƒ†ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (Windows)
- **Visual C++ å†é ’å¸ƒå¯èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**ï¼ˆPythonã¨å…±ã«è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰
- **USB 3.0ãƒ‰ãƒ©ã‚¤ãƒãƒ¼**ï¼ˆé€šå¸¸çµ„ã¿è¾¼ã¿; ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ç¢ºèªï¼‰

---

## ğŸ”§ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
```bash
git clone https://github.com/ShoumikMahbubRidoy/TG_25_GestureOAK-D.git
cd TG_25_GestureOAK-D
git checkout Hand-Gesture  # æ­£ã—ã„ãƒ–ãƒ©ãƒ³ãƒã«ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

**ä»®æƒ³ç’°å¢ƒã‚’ä½¿ã†ç†ç”±**:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾å­˜é–¢ä¿‚ã‚’ã‚·ã‚¹ãƒ†ãƒ Pythonã‹ã‚‰åˆ†é›¢
- ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç«¶åˆã‚’é˜²æ­¢
- å†ç¾å¯èƒ½ãªãƒ“ãƒ«ãƒ‰ã‚’å®Ÿç¾

### ã‚¹ãƒ†ãƒƒãƒ—3: pipã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
```bash
python -m pip install --upgrade pip setuptools wheel
```

---

## ğŸ“¥ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰

### ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
pip install -r requirements.txt
```

**ä¾å­˜é–¢ä¿‚ã®å†…è¨³**:
- **depthai** (â‰¥2.24.0): ãƒ‡ãƒã‚¤ã‚¹é€šä¿¡ãŠã‚ˆã³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†ã®ãŸã‚ã®OAK-D SDK
- **opencv-python** (â‰¥4.8.0): ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ãŠã‚ˆã³è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **numpy** (â‰¥1.24.0): ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¤‰æ›ç”¨æ•°å€¤æ¼”ç®—
- **mediapipe** (â‰¥0.10.0): äº‹å‰å­¦ç¿’æ¸ˆã¿æ‰‹æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ï¼ˆå‚ç…§ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- **imutils** (â‰¥0.5.4): OpenCVæ“ä½œç”¨ä¾¿åˆ©é–¢æ•°
- **pyyaml** (â‰¥6.0): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ãƒ¼ã‚¹ï¼ˆYAMLè¨­å®šä½¿ç”¨æ™‚ï¼‰

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¤œè¨¼
```bash
# Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
python --version  # 3.10.x ã¾ãŸã¯ 3.11.x ã¾ãŸã¯ 3.12.x ã¨è¡¨ç¤ºã•ã‚Œã‚‹ã¹ã

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª
pip list | grep -E "depthai|opencv|numpy"

# OAK-Dæ¥ç¶šãƒ†ã‚¹ãƒˆ
python -c "import depthai as dai; print(dai.__version__); print(dai.Device.getAllAvailableDevices())"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
2.24.0.0  # ã¾ãŸã¯ãã‚Œä»¥é™
[<depthai.DeviceInfo ...>]  # OAK-Dãƒ‡ãƒã‚¤ã‚¹ãŒãƒªã‚¹ãƒˆã•ã‚Œã‚‹ã¹ã
```

### ç’°å¢ƒæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
python probe_dai.py
```

**ãƒã‚§ãƒƒã‚¯å†…å®¹**:
- DepthAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
- OAK-Dãƒ‡ãƒã‚¤ã‚¹ã®åˆ—æŒ™
- USBæ¥ç¶šé€Ÿåº¦
- ã‚«ãƒ¡ãƒ©ã‚»ãƒ³ã‚µãƒ¼ã®å¯ç”¨æ€§

---

## ğŸ›ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 
```
src/gesture_oak/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ oak_camera.py          # ã‚«ãƒ¡ãƒ©æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼
â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hand_detector.py       # MediaPipeãƒ™ãƒ¼ã‚¹æ‰‹æ¤œå‡º
â”‚   â”œâ”€â”€ motion_detector.py     # ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹æ¤œå‡ºï¼ˆä»£æ›¿ï¼‰
â”‚   â”œâ”€â”€ motion_swipe_detector.py
â”‚   â””â”€â”€ swipe_detector.py      # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ãƒ­ã‚¸ãƒƒã‚¯
â”œâ”€â”€ logic/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gesture_classifier.py # æŒ‡ã‚«ã‚¦ãƒ³ãƒˆã€ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hand_tracking_app.py   # ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¢
â”‚   â”œâ”€â”€ swipe_detection_app.py # ã‚¹ãƒ¯ã‚¤ãƒ—å°‚ç”¨ãƒ‡ãƒ¢
â”‚   â””â”€â”€ motion_swipe_app.py    # ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã‚¹ãƒ¯ã‚¤ãƒ—ãƒ‡ãƒ¢
â””â”€â”€ utils/
    â”œâ”€â”€ FPS.py                 # FPSæ¸¬å®š
    â”œâ”€â”€ mediapipe_utils.py     # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€ãƒ˜ãƒ«ãƒ‘ãƒ¼
    â””â”€â”€ template_manager_script_solo.py  # ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

### ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
1. **main.py**: ç•°ãªã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼
2. **run_hand_tracking.py**: ãƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ—ãƒªã®ç›´æ¥å®Ÿè¡Œ
3. **TG25_Launcher.py**: å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ç”¨GUIãƒ©ãƒ³ãƒãƒ£ãƒ¼
4. **probe_dai.py**: ãƒ‡ãƒã‚¤ã‚¹è¨ºæ–­ãƒ„ãƒ¼ãƒ«

---

## ğŸš€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ

### æ–¹æ³•1: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆæ¨å¥¨ï¼‰
```bash
python main.py
```

**ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:
```
1. Test camera connection        # OAK-Dã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¤œè¨¼
2. Run hand tracking app         # ãƒ•ãƒ«æ©Ÿèƒ½æ‰‹æ¤œå‡º + ã‚¹ãƒ¯ã‚¤ãƒ—
3. Run swipe detection app       # ã‚¹ãƒ¯ã‚¤ãƒ—å°‚ç”¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
4. Run motion-based swipe        # ä»£æ›¿ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡º
5. Exit
```

**ä½¿ç”¨å ´é¢**:
- **ã‚ªãƒ—ã‚·ãƒ§ãƒ³1**: åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€æ¥ç¶šå•é¡Œã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- **ã‚ªãƒ—ã‚·ãƒ§ãƒ³2**: é–‹ç™ºã€ãƒ‡ãƒãƒƒã‚°ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **ã‚ªãƒ—ã‚·ãƒ§ãƒ³3**: æœ¬ç•ªã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡º
- **ã‚ªãƒ—ã‚·ãƒ§ãƒ³4**: å®Ÿé¨“çš„ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

### æ–¹æ³•2: ç›´æ¥å®Ÿè¡Œ
```bash
# ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºä»˜ããƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
python run_hand_tracking.py

# ã¾ãŸã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµŒç”±
python -m gesture_oak.apps.hand_tracking_app
```

### æ–¹æ³•3: UVä½¿ç”¨ï¼ˆé«˜é€ŸPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰
```bash
# uvãŒã¾ã ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ
pip install uv

# uvã§å®Ÿè¡Œï¼ˆé«˜é€Ÿèµ·å‹•ï¼‰
uv run python main.py
```

### ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ¶å¾¡

#### ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
- **`q`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†
- **`s`**: ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã«ä¿å­˜ï¼ˆJPEGå½¢å¼ï¼‰
- **`r`**: ã‚¹ãƒ¯ã‚¤ãƒ—çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆ

#### ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
```
OAK-D Hand Detection Demo with Swipe Detection
=============================================
Press 'q' to quit
Press 's' to save current frame
Press 'r' to reset swipe statistics

Connected to device: OAK-D-PRO
USB Speed: SUPER_SPEED
Hand detection started. Showing live preview...

Hand 1: right (confidence: 0.957)
  Gesture: FIVE
 LEFT-TO-RIGHT SWIPE DETECTED! (Total: 1)
```

### æœŸå¾…ã•ã‚Œã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- **FPS**: 25ã€œ30 FPSï¼ˆOAK-D-PRO IRãƒ¢ãƒ¼ãƒ‰ï¼‰
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: ã€œ50ã€œ80msï¼ˆã‚«ãƒ¡ãƒ©ã‹ã‚‰è¡¨ç¤ºã¾ã§ï¼‰
- **æ¤œå‡ºç¯„å›²**: 80ã€œ160 cm æœ€é©ã€40ã€œ200 cm æ‹¡å¼µ
- **ã‚¹ãƒ¯ã‚¤ãƒ—æˆåŠŸç‡**: è‰¯å¥½ãªæ¡ä»¶ä¸‹ã§ã€œ95%

---

## ğŸ—‚ï¸ å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.exeï¼‰ã®å–ã‚Šæ‰±ã„

### å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ“ãƒ«ãƒ‰

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ **PyInstaller** ã‚’ä½¿ç”¨ã—ã¦Windowså±•é–‹ç”¨ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ¼ãƒ³å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

#### ãƒ“ãƒ«ãƒ‰å‰ææ¡ä»¶
```bash
pip install pyinstaller
```

#### ãƒ“ãƒ«ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

##### 1. ãƒãƒ³ãƒ‰ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãƒ“ãƒ«ãƒ‰
```bash
# Windows
build.bat

# ã¾ãŸã¯æ‰‹å‹•ã§
pyinstaller run_hand_tracking.spec
```

**Specãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ©ã‚¤ãƒˆ** (`run_hand_tracking.spec`):
```python
a = Analysis(
    ['run_hand_tracking.py'],
    pathex=[],
    binaries=[],
    datas=[
        ('models', 'models'),  # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯blobã‚’ãƒãƒ³ãƒ‰ãƒ«
        ('src/gesture_oak/utils/template_manager_script_solo.py',
         'src/gesture_oak/utils'),
    ],
    hiddenimports=[
        'depthai',
        'cv2',
        'numpy',
        # ... ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚
    ],
    ...
)
```

##### 2. ãƒ©ãƒ³ãƒãƒ£ãƒ¼GUIã®ãƒ“ãƒ«ãƒ‰
```bash
pyinstaller TG25_Launcher.spec
```

##### 3. è¨ºæ–­ãƒ„ãƒ¼ãƒ«ã®ãƒ“ãƒ«ãƒ‰
```bash
pyinstaller probe_dai.spec
```

### å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®é…å¸ƒ

ãƒ“ãƒ«ãƒ‰å¾Œã€`dist/` ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:
```
dist/
â”œâ”€â”€ TG25_HandTracking/
â”‚   â”œâ”€â”€ TG25_HandTracking.exe  # ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ models/                # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯blob
â”‚   â””â”€â”€ [ä¾å­˜é–¢ä¿‚]             # DLLã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”œâ”€â”€ TG25_Launcher.exe          # GUIãƒ©ãƒ³ãƒãƒ£ãƒ¼
â””â”€â”€ probe_dai.exe              # è¨ºæ–­ãƒ„ãƒ¼ãƒ«
```

### å±•é–‹æ‰‹é †

1. **ãƒ•ã‚©ãƒ«ãƒ€å…¨ä½“ã‚’ã‚³ãƒ”ãƒ¼** ã—ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚·ãƒ³ã¸:
   ```
   TG25_GestureOAK-D_Deployment/
   â”œâ”€â”€ TG25_Launcher.exe
   â”œâ”€â”€ TG25_HandTracking.exe
   â”œâ”€â”€ models/
   â””â”€â”€ (dist/ã‹ã‚‰ã®ã™ã¹ã¦ã®DLL)
   ```

2. **`TG25_Launcher.exe` ã‚’å®Ÿè¡Œ** ã—ã¦GUIã‚’èµ·å‹•

3. **ã€ŒStart Hand Trackingã€ã‚’ã‚¯ãƒªãƒƒã‚¯** ã—ã¦ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•

### å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### å•é¡Œ: ã€Œmodelsãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€
**è§£æ±ºç­–**: `models/` ãŒ `.exe` ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

#### å•é¡Œ: ã€ŒImport Error: No module named 'depthai'ã€
**è§£æ±ºç­–**: PyInstallerãŒä¾å­˜é–¢ä¿‚ã‚’è¦‹é€ƒã—ãŸå¯èƒ½æ€§ã€‚`.spec` ãƒ•ã‚¡ã‚¤ãƒ«ã® `hiddenimports` ã«è¿½åŠ :
```python
hiddenimports=[
    'depthai',
    'depthai._version',  # ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 
    ...
]
```

#### å•é¡Œ: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã«åœæ­¢ã—ãªã„
**è§£æ±ºç­–**: åœæ­¢ãƒ•ãƒ©ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèª:
```python
# TG25_Launcher.pyå†…
stop_file = Path(_exe_dir()) / "TG25_STOP.flag"

# run_hand_tracking.pyå†…
stop_file_path = os.environ.get("TG25_STOP_FILE", "")
```

---

## ğŸ› ï¸ å®Ÿè£…ã®è©³ç´°

### æ‰‹æ¤œå‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### 1. ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
```python
# hand_detector.py
cam_left = pipeline.createMonoCamera()
cam_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
cam_left.setBoardSocket(dai.CameraBoardSocket.LEFT)
cam_left.setFps(30)

cam_right = pipeline.createMonoCamera()
cam_right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
cam_right.setBoardSocket(dai.CameraBoardSocket.RIGHT)
cam_right.setFps(30)
```

**IRã‚«ãƒ¡ãƒ©ã‚’ä½¿ã†ç†ç”±**:
- ä½ç…§åº¦ã§ä¸€è²«ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- è‰²å¤‰åŒ–ï¼ˆè‚Œè‰²ã€è¡£æœï¼‰ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„
- ãƒã‚¤ãƒ†ã‚£ãƒ–400pè§£åƒåº¦ãŒMediaPipeå…¥åŠ›è¦ä»¶ã¨ä¸€è‡´

#### 2. ã‚¹ãƒ†ãƒ¬ã‚ªæ·±åº¦è¨­å®š
```python
depth = pipeline.createStereoDepth()
depth.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
depth.initialConfig.setMedianFilter(dai.MedianFilter.KERNEL_7x7)
depth.setLeftRightCheck(True)    # ç„¡åŠ¹ãªè¦–å·®ã‚’æ’é™¤
depth.setSubpixel(True)          # æ·±åº¦ç²¾åº¦ã‚’å‘ä¸Š
```

**æŠ€è¡“èª¬æ˜**:
- **HIGH_DENSITY**: å°ç‰©ä½“ï¼ˆæ‰‹ï¼‰ã®ã‚ã‚‹å±‹å†…ã‚·ãƒ¼ãƒ³ç”¨ã«æœ€é©åŒ–
- **7Ã—7ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: æ·±åº¦ãƒãƒƒãƒ—ã‹ã‚‰ã‚¹ãƒšãƒƒã‚¯ãƒ«ãƒã‚¤ã‚ºã‚’é™¤å»
- **Left-Right Check**: ã‚¹ãƒ†ãƒ¬ã‚ªãƒšã‚¢é–“ã®è¦–å·®ä¸€è²«æ€§ã‚’æ¤œè¨¼
- **Subpixel**: ã‚ˆã‚Šæ»‘ã‚‰ã‹ãªæ·±åº¦ã®ãŸã‚ã«åˆ†æ•°è¦–å·®å€¤ã‚’æœ‰åŠ¹åŒ–

#### 3. IRãƒ•ãƒ¬ãƒ¼ãƒ å¼·èª¿å‡¦ç†
```python
def enhance_ir_frame(self, frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
    
    # CLAHEï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆåˆ¶é™é©å¿œãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–ï¼‰
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚¨ãƒƒã‚¸ä¿å­˜å¹³æ»‘åŒ–ï¼‰
    enhanced = cv2.bilateralFilter(enhanced, 5, 50, 50)
    
    return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)
```

**ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ãŸç†ç”±**:
- **CLAHE**: ãƒã‚¤ã‚ºã‚’éåº¦ã«å¢—å¹…ã›ãšã«å±€æ‰€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·èª¿
- **clipLimit=2.0**: å‡è³ªé ˜åŸŸã§ã®éåº¦ã®å¢—å¹…ã‚’é˜²æ­¢
- **tileGridSize=(8,8)**: å±€æ‰€ã¨å…¨ä½“ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹
- **ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: æ‰‹ã®ã‚¨ãƒƒã‚¸ã‚’ä¿æŒã—ãªãŒã‚‰ãƒã‚¤ã‚ºã‚’å¹³æ»‘åŒ–

#### 4. æ·±åº¦ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
```python
def filter_hands_by_depth(self, hands, depth_frame):
    for hand in hands:
        cx, cy = hand.rect_x_center_a, hand.rect_y_center_a
        d_center = depth_frame[cy, cx]
        
        # æœ‰åŠ¹ç¯„å›²: 300ã€œ2000mmï¼ˆ30cm - 2mï¼‰
        if not (300 <= d_center <= 2000):
            continue
        
        # æ‰‹ä¸­å¿ƒå‘¨è¾ºã®é–¢å¿ƒé ˜åŸŸ
        half = 18 if d_center < 1000 else 26  # é ã„æ‰‹ã«ã¯å¤§ãã„ROI
        roi = depth_frame[cy-half:cy+half, cx-half:cx+half]
        
        avg = np.mean(roi[roi > 0])
        std = np.std(roi[roi > 0])
        
        # è·é›¢å¯¾å¿œè¨±å®¹å€¤
        std_limit = 80.0 + 0.08 * max(0.0, (avg - 800.0))
        if std <= std_limit:
            hand.depth = avg
            hand.depth_confidence = 1.0 - (std / std_limit)
```

**æŠ€è¡“çš„æ ¹æ‹ **:
- **å¯å¤‰std_limit**: é ã„æ‰‹ã¯æ·±åº¦ç²¾åº¦ãŒä½ã„
- **ROIã‚µã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: ç•°ãªã‚‹è·é›¢ã§ã®æ‰‹ã®è¦‹ã‹ã‘ã‚µã‚¤ã‚ºã«é©å¿œ
- **ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: æ·±åº¦æ¸¬å®šã®ä¿¡é ¼æ€§ã‚’å®šé‡åŒ–

### ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

#### çŠ¶æ…‹é·ç§»ãƒ­ã‚¸ãƒƒã‚¯
```python
IDLE:
    - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãæ‰‹ä½ç½®ã‚’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
    - ä¸€è²«ã—ãŸå³æ–¹å‘å‹•ä½œã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆé€£ç¶š3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
    - å‹•ä½œæ¤œå‡ºæ™‚ã«DETECTINGã«é·ç§»

DETECTING:
    - è»Œè·¡ã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚’ç¶™ç¶š
    - ç´¯ç©è·é›¢ã‚’è¨ˆç®—
    - æŒç¶šæ™‚é–“ > max_durationï¼ˆ2.0ç§’ï¼‰ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    - å·¦ã¸ã®å‹•ãã§ä¸­æ­¢
    - è·é›¢ >= min_distanceï¼ˆ90pxï¼‰æ™‚ã«VALIDATINGã«é·ç§»

VALIDATING:
    - æŒç¶šæ™‚é–“ãŒ[0.2ç§’ã€2.0ç§’]å†…ã§ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨¼
    - å¹³å‡é€Ÿåº¦ã‚’è¨ˆç®—: è·é›¢ / æŒç¶šæ™‚é–“
    - é€Ÿåº¦ç¯„å›²[35 px/sã€900 px/s]ã‚’ãƒã‚§ãƒƒã‚¯
    - Yè»¸åå·® â‰¤ Xç§»å‹•ã®35%ã‚’æ¤œè¨¼
    - æœ‰æ„ãªå¾Œé€€å‹•ä½œãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆ< -12pxã‚¸ãƒ£ãƒ³ãƒ—ï¼‰
    - ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ãŒé€šéã—ãŸå ´åˆCONFIRMEDã«é·ç§»

CONFIRMED:
    - ã‚¹ãƒ¯ã‚¤ãƒ—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åˆ†
    - 192.168.10.10:6001ã¸UDPãƒ‘ã‚±ãƒƒãƒˆã€ŒSwipeã€ã‚’é€ä¿¡
    - ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆ0.8ç§’ï¼‰ã‚’é©ç”¨ã—ã¦æ€¥é€Ÿãªå†ãƒˆãƒªã‚¬ãƒ¼ã‚’é˜²æ­¢
    - IDLEã«æˆ»ã‚‹
```

#### é€Ÿåº¦è¨ˆç®—
```python
# FPSéä¾å­˜é€Ÿåº¦ï¼ˆãƒ”ã‚¯ã‚»ãƒ«æ¯ç§’ï¼‰
times = np.array(self.time_buffer)
poses = np.array(self.position_buffer)

total_dx = poses[-1, 0] - poses[0, 0]  # æ°´å¹³å¤‰ä½
duration = times[-1] - times[0]        # çµŒéæ™‚é–“
velocity = total_dx / duration         # px/s
```

**ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ã†ç†ç”±**:
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆå¤‰å‹•ã«ä¾å­˜ã—ãªã„
- ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é©åˆ‡ã«å‡¦ç†
- æ­£ç¢ºãªé€Ÿåº¦æ¸¬å®šã‚’æä¾›

---

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: ã‚«ãƒ¡ãƒ©ãŒæ¤œå‡ºã•ã‚Œãªã„

**ç—‡çŠ¶**:
```
Failed to connect to OAK-D: [X_LINK_DEVICE_NOT_FOUND]
```

**è§£æ±ºç­–**:

1. **USBæ¥ç¶šã‚’ç¢ºèª**:
   ```bash
   # Linux
   lsusb | grep "03e7"  # Luxonis VID
   
   # Windowsï¼ˆãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰
   # USBãƒ‡ãƒã‚¤ã‚¹ä¸‹ã§ã€ŒMovidius MyriadXã€ã¾ãŸã¯ã€ŒOAK-Dã€ã‚’æ¢ã™
   ```

2. **USBãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æ›´æ–°**ï¼ˆWindowsï¼‰:
   - Zadigã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: https://zadig.akeo.ie/
   - ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’WinUSBã«ç½®ãæ›ãˆ

3. **USBæ¨©é™ã‚’ä»˜ä¸**ï¼ˆLinuxï¼‰:
   ```bash
   echo 'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"' | sudo tee /etc/udev/rules.d/80-movidius.rules
   sudo udevadm control --reload-rules && sudo udevadm trigger
   ```

4. **è¨ºæ–­ãƒ„ãƒ¼ãƒ«ã§ãƒ†ã‚¹ãƒˆ**:
   ```bash
   python probe_dai.py
   ```

### å•é¡Œ2: ä½FPS / ã‚«ã‚¯ã¤ã

**ç—‡çŠ¶**:
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆãŒ20 FPSæœªæº€ã«ä½ä¸‹
- ã‚«ãƒ¡ãƒ©ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã‚«ã‚¯ã‚«ã‚¯

**è§£æ±ºç­–**:

1. **USBé€Ÿåº¦ã‚’ç¢ºèª**:
   ```python
   # USB3 SUPER_SPEEDã¾ãŸã¯SUPER_PLUSã¨è¡¨ç¤ºã•ã‚Œã‚‹ã¹ã
   device.getUsbSpeed()
   ```

2. **ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›**ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã—ã¦ã„ã‚‹å ´åˆï¼‰:
   ```python
   # hand_detector.pyå†…
   self.q_video = self.device.getOutputQueue(
       name="cam_out", 
       maxSize=2,  # 4ã‹ã‚‰2ã«å‰Šæ¸›
       blocking=False
   )
   ```

3. **IRå¼·èª¿å‡¦ç†ã‚’ç„¡åŠ¹åŒ–**ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰:
   ```python
   # hand_detector.pyå†…ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
   # frame = self.enhance_ir_frame(raw_frame)
   frame = raw_frame
   ```

4. **OpenCVã‚’æœ€é©åŒ–**:
   ```python
   import cv2
   cv2.setUseOptimized(True)
   cv2.setNumThreads(0)  # æœ€é©ãªã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’è‡ªå‹•æ¤œå‡º
   ```

### å•é¡Œ3: èª¤æ¤œå‡ºã‚¹ãƒ¯ã‚¤ãƒ—

**ç—‡çŠ¶**:
- æ‰‹ã®å‹•ããªã—ã«ã‚¹ãƒ¯ã‚¤ãƒ—ãŒãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã‚‹
- ãƒ©ãƒ³ãƒ€ãƒ ãªç‰©ä½“ãŒæ¤œå‡ºã‚’å¼•ãèµ·ã“ã™

**è§£æ±ºç­–**:

1. **æœ€å°è·é›¢ã‚’å¢—ã‚„ã™**:
   ```python
   swipe_detector = SwipeDetector(
       min_distance=120,  # 90ã‹ã‚‰å¢—åŠ 
   )
   ```

2. **ã‚ˆã‚Šå³ã—ã„Yåå·®**:
   ```python
   swipe_detector = SwipeDetector(
       max_y_deviation=0.25,  # 0.35ã‹ã‚‰å‰Šæ¸›
   )
   ```

3. **é€Ÿåº¦ç¯„å›²ã‚’ç‹­ã‚ã‚‹**:
   ```python
   swipe_detector = SwipeDetector(
       min_velocity=50,   # 35ã‹ã‚‰å¢—åŠ 
       max_velocity=700,  # 900ã‹ã‚‰å‰Šæ¸›
   )
   ```

4. **ã‚ˆã‚Šå³ã—ã„æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–**:
   ```python
   # hand_detector.pyå†…
   std_limit = 60.0 + 0.06 * max(0.0, (avg - 800.0))  # è¨±å®¹å€¤ã‚’å‰Šæ¸›
   ```

### å•é¡Œ4: è·é›¢ã§æ‰‹ãŒæ¤œå‡ºã•ã‚Œãªã„

**ç—‡çŠ¶**:
- ç”»é¢ä¸Šã«æ‰‹ãŒè¦‹ãˆã‚‹ãŒ100+ cmã§æ¤œå‡ºã•ã‚Œãªã„
- è¿‘è·é›¢ï¼ˆ<80 cmï¼‰ã§ã®ã¿å‹•ä½œ

**è§£æ±ºç­–**:

1. **ãƒ‘ãƒ¼ãƒ æ¤œå‡ºé–¾å€¤ã‚’ä¸‹ã’ã‚‹**:
   ```python
   detector = HandDetector(
       pd_score_thresh=0.08,  # 0.10ã‹ã‚‰å‰Šæ¸›
   )
   ```

2. **ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã™**ï¼ˆå±¥æ­´ã‚’å¢—ã‚„ã™ï¼‰:
   ```python
   swipe_detector = SwipeDetector(
       buffer_size=24,  # 18ã‹ã‚‰å¢—åŠ 
   )
   ```

3. **æ·±åº¦ç¯„å›²ã‚’èª¿æ•´**:
   ```python
   # hand_detector.py - filter_hands_by_depth()å†…
   if not (200 <= d_center <= 2500):  # ç¯„å›²ã‚’æ‹¡å¼µ
   ```

4. **IRç…§æ˜ã‚’ç¢ºèª**:
   - OAK-D-PROã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–IRã‚¨ãƒŸãƒƒã‚¿ãƒ¼ã‚’æŒã¤
   - IR LEDãŒè¦‹ãˆã‚‹ã‹ç¢ºèªï¼ˆã‚¹ãƒãƒ›ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ï¼‰

### å•é¡Œ5: å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã§ã€ŒImportErrorã€

**ç—‡çŠ¶**:
```
ImportError: No module named 'depthai'
ModuleNotFoundError: No module named 'cv2'
```

**è§£æ±ºç­–**:

1. **ã™ã¹ã¦ã®éš ã—ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§å†ãƒ“ãƒ«ãƒ‰**:
   ```python
   # .specãƒ•ã‚¡ã‚¤ãƒ«å†…
   hiddenimports=[
       'depthai',
       'cv2',
       'numpy',
       'numpy.core',
       'numpy.core._multiarray_umath',
       'mediapipe',
       'marshal',
       'collections',
       'collections.abc',
       'socket',
       'time',
       'pathlib',
   ]
   ```

2. **ãƒã‚¤ãƒŠãƒªä¾å­˜é–¢ä¿‚ã‚’ãƒãƒ³ãƒ‰ãƒ«**:
   ```python
   # .specãƒ•ã‚¡ã‚¤ãƒ«å†…
   binaries=[
       (r'C:\path\to\.venv\Lib\site-packages\depthai\*.dll', 'depthai'),
   ]
   ```

3. **PyInstallerãƒ•ãƒƒã‚¯ã‚’ä½¿ç”¨**:
   ```bash
   pip install pyinstaller-hooks-contrib
   pyinstaller --additional-hooks-dir=. run_hand_tracking.spec
   ```

### å•é¡Œ6: UDPãƒ‘ã‚±ãƒƒãƒˆãŒå—ä¿¡ã•ã‚Œãªã„

**ç—‡çŠ¶**:
- ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡ºã•ã‚ŒãŸãŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãªã—
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒã€ŒSwipeã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ãªã„

**è§£æ±ºç­–**:

1. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆã‚’ç¢ºèª**:
   ```bash
   # UDPæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ
   # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆ192.168.10.10ï¼‰ã§:
   nc -u -l 6001
   
   # ã‚½ãƒ¼ã‚¹ãƒã‚·ãƒ³ã§:
   echo "test" | nc -u 192.168.10.10 6001
   ```

2. **ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ãƒ«ãƒ¼ãƒ«ã‚’ç¢ºèª**:
   ```bash
   # Windows
   netsh advfirewall firewall add rule name="Allow UDP 6001" dir=out action=allow protocol=UDP localport=6001
   
   # Linux
   sudo ufw allow out 6001/udp
   ```

3. **ã‚½ã‚±ãƒƒãƒˆã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ**:
   ```python
   import socket
   sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
   sock.sendto(b"Test", ("192.168.10.10", 6001))
   print("ãƒ†ã‚¹ãƒˆãƒ‘ã‚±ãƒƒãƒˆé€ä¿¡")
   ```

4. **ã‚½ã‚±ãƒƒãƒˆãƒ‡ãƒãƒƒã‚°ã‚’æœ‰åŠ¹åŒ–**:
   ```python
   # swipe_detector.pyå†…
   try:
       self._udp_sock.sendto(b"Swipe", self._udp_target)
       print(f"UDPé€ä¿¡: {self._udp_target}")
   except Exception as e:
       print(f"UDPã‚¨ãƒ©ãƒ¼: {e}")
   ```

### å•é¡Œ7: ãƒ©ãƒ³ãƒãƒ£ãƒ¼ãŒãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã§ããªã„

**ç—‡çŠ¶**:
- ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ãŒãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†ã—ãªã„
- ãƒ©ãƒ³ãƒãƒ£ãƒ¼çµ‚äº†å¾Œã‚‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ãŒæ®‹ã‚‹

**è§£æ±ºç­–**:

1. **åœæ­¢ãƒ•ãƒ©ã‚°ãƒ‘ã‚¹ã‚’æ¤œè¨¼**:
   ```python
   # TG25_Launcher.pyå†…
   print(f"åœæ­¢ãƒ•ãƒ©ã‚°: {self.stop_file}")
   
   # run_hand_tracking.pyå†…
   stop_file_path = os.environ.get("TG25_STOP_FILE", "")
   print(f"åœæ­¢ãƒ•ãƒ©ã‚°ç›£è¦–ä¸­: {stop_file_path}")
   ```

2. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ¨©é™ã‚’ç¢ºèª**:
   ```bash
   # ãƒ©ãƒ³ãƒãƒ£ãƒ¼ãŒä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ›¸ãè¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
   touch TG25_STOP.flag && rm TG25_STOP.flag
   ```

3. **å¼·åˆ¶çµ‚äº†**ï¼ˆæœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ï¼‰:
   ```python
   # TG25_Launcher.py - stop_worker()å†…
   import psutil
   try:
       proc = psutil.Process(self.proc.pid)
       for child in proc.children(recursive=True):
           child.kill()
       proc.kill()
   except Exception as e:
       print(f"å¼·åˆ¶çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}")
   ```

---

## âš ï¸ æ—¢çŸ¥ã®å•é¡Œ

### 1. FPSã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ç•°å¸¸
**èª¬æ˜**: æ™‚ã€…éç¾å®Ÿçš„ãªFPSï¼ˆ>100,000ï¼‰ã‚’å ±å‘Š  
**æ ¹æœ¬åŸå› **: `elapsed < 1e-6` æ™‚ã®ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨ˆç®—ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹  
**å½±éŸ¿**: è¦–è¦šçš„ã®ã¿; ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¯å½±éŸ¿ãªã—  
**å›é¿ç­–**: ä»£ã‚ã‚Šã«ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡FPSã‚’ä½¿ç”¨  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ä½å„ªå…ˆåº¦ä¿®æ­£

### 2. å·¦æ‰‹æ¤œå‡ºã®ä¸å®‰å®šæ€§
**èª¬æ˜**: 100 cmä»¥ä¸Šã§ã¯å·¦æ‰‹ã®ä¿¡é ¼æ€§ãŒä½ã„  
**æ ¹æœ¬åŸå› **: MediaPipeãƒ¢ãƒ‡ãƒ«ã®å³æ‰‹ã¸ã®ãƒã‚¤ã‚¢ã‚¹  
**å½±éŸ¿**: å·¦æ‰‹ã®æ¤œå‡ºç¯„å›²ãŒç¸®å°  
**å›é¿ç­–**: é è·é›¢æ“ä½œã«ã¯å³æ‰‹ã‚’ä½¿ç”¨  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æŸ»ä¸­

### 3. èƒŒæ™¯èª¤æ¤œå‡º
**èª¬æ˜**: è¡£æœã€é«ªã€ã¾ãŸã¯è€³ãŒæ™‚ã€…æ‰‹æ¤œå‡ºã‚’ãƒˆãƒªã‚¬ãƒ¼  
**æ ¹æœ¬åŸå› **: IRåå°„ç‡ã®é¡ä¼¼æ€§  
**å½±éŸ¿**: æ™‚æŠ˜ã®èª¤æ¤œå‡º  
**å›é¿ç­–**: æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚ˆã‚Šå³ã—ã„é–¾å€¤ã‚’ä½¿ç”¨  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ç¶™ç¶šçš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­

### 4. æ·±åº¦ãƒãƒƒãƒ—ã®ç©´
**èª¬æ˜**: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹å®šé ˜åŸŸã§æ·±åº¦ãŒåˆ©ç”¨ä¸å¯  
**æ ¹æœ¬åŸå› **: ã‚¹ãƒ†ãƒ¬ã‚ªç”»åƒã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¸è¶³  
**å½±éŸ¿**: ä¸€éƒ¨ã®æœ‰åŠ¹ãªæ‰‹ãŒæ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§å¤±æ•—  
**å›é¿ç­–**: `std_limit` è¨±å®¹å€¤ã‚’ä¸‹ã’ã‚‹  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ¶é™

---

## ğŸ—ºï¸ ä»Šå¾Œã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### ãƒ•ã‚§ãƒ¼ã‚º1: ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼æ‹¡å¼µï¼ˆ2024å¹´Q2ï¼‰
- [ ] æŒ‡ã‚«ã‚¦ãƒ³ãƒˆèªè­˜ï¼ˆ1-5ï¼‰
- [ ] é™çš„ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ï¼ˆãƒ”ãƒ¼ã‚¹ã€ã‚µãƒ ã‚ºã‚¢ãƒƒãƒ—ã€OKï¼‰
- [ ] æ‹³/æ‰‹ã®ã²ã‚‰é–‹é–‰æ¤œå‡º
- [ ] å‹•çš„ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªå½™

### ãƒ•ã‚§ãƒ¼ã‚º2: ä¸¡æ‰‹ã‚µãƒãƒ¼ãƒˆï¼ˆ2024å¹´Q3ï¼‰
- [ ] 2ã¤ã®æ‰‹ã®åŒæ™‚è¿½è·¡
- [ ] æ‰‹-æ‰‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼
- [ ] å”èª¿ã‚¹ãƒ¯ã‚¤ãƒ—æ¤œå‡º

### ãƒ•ã‚§ãƒ¼ã‚º3: å …ç‰¢æ€§å‘ä¸Šï¼ˆ2024å¹´Q4ï¼‰
- [ ] ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†
- [ ] å¾®èª¿æ•´ã•ã‚ŒãŸMediaPipeãƒ¢ãƒ‡ãƒ«
- [ ] ç’°å¢ƒãƒ™ãƒ¼ã‚¹ã®é©å¿œé–¾å€¤è¨­å®š
- [ ] èª¤æ¤œå‡ºå‰Šæ¸›ã®ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’

### ãƒ•ã‚§ãƒ¼ã‚º4: æ‹¡å¼µæ©Ÿèƒ½ï¼ˆ2025å¹´ï¼‰
- [ ] ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ãŸ3Dã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜
- [ ] ãƒãƒ¼ã‚ºæ¨å®šçµ±åˆ
- [ ] ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ãƒã‚¯ãƒ­ã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
- [ ] Web UIçµŒç”±ã®ãƒªãƒ¢ãƒ¼ãƒˆè¨­å®š

### ãƒ•ã‚§ãƒ¼ã‚º5: æœ€é©åŒ–ï¼ˆç¶™ç¶šä¸­ï¼‰
- [ ] FPSã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ä¿®æ­£
- [ ] ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’<30msã«å‰Šæ¸›
- [ ] å‰å‡¦ç†ã®ãŸã‚ã®GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ã‚«ã‚¹ã‚¿ãƒ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‡å­åŒ–

---

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

---

## ğŸ‘¥ è²¢çŒ®

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­“è¿ã—ã¾ã™ã€‚å¤§ããªå¤‰æ›´ã®å ´åˆã¯ã€ã¾ãšissueã‚’é–‹ã„ã¦å¤‰æ›´å†…å®¹ã‚’è­°è«–ã—ã¦ãã ã•ã„ã€‚

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆ:
1. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°-1)ã‚’ç¢ºèª
2. [æ—¢çŸ¥ã®å•é¡Œ](#æ—¢çŸ¥ã®å•é¡Œ-1)ã‚’ç¢ºèª
3. GitHubã§issueã‚’ä½œæˆ
4. è©³ç´°ãƒ­ã‚°ã¨ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å«ã‚ã‚‹

---

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¶­æŒ**: ShoumikMahbubRidoy  
**ãƒªãƒã‚¸ãƒˆãƒª**: https://github.com/ShoumikMahbubRidoy/TG_25_GestureOAK-D  
**ãƒ–ãƒ©ãƒ³ãƒ**: Hand-Gesture